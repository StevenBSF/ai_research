以下给出针对这 5 个问题的要点式参考回答，供学习或整理讲义使用。内容仅做概要性阐述，可根据需要进行适当扩展或细化。



**1. 人工智能主要研究方法有哪些？列举至少 3 个人工智能的研究领域**



**人工智能（AI）** 是一门交叉学科，涵盖多种理论与方法，常见的主要研究领域和方法包括（不限于以下）：

​	1.	**机器学习（Machine Learning）**

​	•	让计算机通过数据学习规律，包括监督学习、无监督学习、强化学习等多种范式。

​	2.	**知识表示与推理（Knowledge Representation and Reasoning）**

​	•	用符号或图结构表示事实、规则，利用逻辑或概率推理算法进行推理决策。

​	3.	**自然语言处理（NLP）**

​	•	研究计算机对人类语言的理解与生成，包括词法分析、句法分析、语义分析、机器翻译、对话系统等。

​	4.	**计算机视觉（Computer Vision）**

​	•	让计算机从图像/视频等视觉数据中提取语义信息，包括目标检测、图像识别、图像分割等。

​	5.	**机器人学（Robotics）**

​	•	综合感知、规划、控制等模块，让机器人具有自主决策和动作执行能力。



**2. 什么是知识图谱？知识图谱的表示及物理存储方法主要有哪些？**

​	•	**知识图谱（Knowledge Graph）**

指用网络/图的形式来表示各类实体（节点）及它们之间的关联关系（边），从而形成一个可机读的“语义网络”。其核心是三元组表示法 ，或称 RDF（Resource Description Framework）格式。

​	•	**表示方法**

​	1.	**RDF 三元组**：主体—谓词—客体。

​	2.	**图数据库模型**：实体作为节点、关系作为边，附带标签与属性。

​	3.	**本体（Ontology）**：进一步定义概念层次、约束条件、逻辑规则等。

​	•	**物理存储方式**

​	1.	**关系型数据库**：用类似“主键-外键”的关系表去存储 RDF；但查询和推理可能较复杂。

​	2.	**图数据库（Graph Database）**：如 Neo4j、JanusGraph 等，原生支持图结构的存储与检索，可高效执行图遍历和模式匹配。

​	3.	**NoSQL 存储**：如键值数据库、文档数据库，也可用于存储与索引三元组数据。



**3. 图示说明在机器学习中过拟合（Overfitting）问题，给出神经网络和决策树的处理方法**

​	1.	**过拟合（Overfitting）现象**

​	•	模型在训练数据上表现很好，但在测试或实际应用中泛化能力差。通常表现为训练误差过低而验证误差较高。

​	2.	**在神经网络中的应对方法**

​	•	**正则化**：在损失函数中加入  或  正则项，抑制权重过大。

​	•	**Dropout**：在训练过程中随机屏蔽部分神经元，减少对局部特征的过度依赖。

​	•	**早停（Early Stopping）**：监控验证集上的误差并在其出现反弹时停止训练。

​	•	**数据增强**：对训练数据进行随机变换或扩充，以提升模型鲁棒性。

​	3.	**在决策树中的应对方法**

​	•	**剪枝（Pruning）**：在生成完一棵“过深”或“过拟合”的决策树后，通过代价复杂度剪枝、或最小错误率剪枝等方法，去掉一些不必要的分支。

​	•	**最小样本分裂数/最大深度限制**：在建树时设置超参数，防止树无限细化。

​	•	**集成方法**：随机森林或梯度提升树等，通过集成多个子树降低过拟合风险。



**4. 简述卷积神经网络的结构，并简述卷积的主要参数**



**卷积神经网络（Convolutional Neural Network, CNN）** 是一种深度学习模型，主要由以下层次构成：

​	1.	**输入层**：接收原始数据（通常是图像的像素矩阵）。

​	2.	**卷积层**：用若干卷积核（filter）在输入特征图上滑动做卷积运算，提取局部特征。

​	3.	**激活函数层**：如 ReLU 等，增强非线性表达能力。

​	4.	**池化层（Pooling）**：对卷积后的特征图做降采样操作（如最大池化/平均池化）。

​	5.	**全连接层（Fully Connected）**：在网络后端将提取到的特征映射到分类或回归输出。

​	6.	**输出层**：如 softmax 单元，用于得到分类概率。



**卷积的主要参数**

​	•	**卷积核（Filter）大小**：如 。

​	•	**步幅（Stride）**：卷积核滑动步长，影响输出特征图大小。

​	•	**填充（Padding）**：对输入在边缘进行零填充，以控制输出大小或保留边缘信息。

​	•	**卷积核数量（#Filters）**：决定输出特征图的深度。

​	•	**通道数（Channels）**：对于彩色图像通常为 3 通道 (RGB)；每个卷积核对所有通道进行卷积再求和。



**5. 简述 DBSCAN 算法**



**DBSCAN（Density-Based Spatial Clustering of Applications with Noise）** 是一种基于密度的聚类算法，核心思想如下：

​	1.	**主要参数**

​	•	（邻域半径）：判断某点周围是否还有足够多的点。

​	•	（最小样本数）：若在某点的  邻域内有至少  个样本，则该点为“核心点”。

​	2.	**聚类过程**

​	•	**核心点（Core Point）**：其  邻域内的点数 ≥ 。

​	•	**边界点（Border Point）**：不满足核心点条件，但落在某个核心点的  邻域之内。

​	•	**噪音点（Noise Point）**：既不是核心点，也不属于任何核心点的邻域。

​	•	算法先找到所有核心点并把它们相互可达的区域合并成簇，然后把边界点归并到相应簇，噪音点则独立存在。

​	3.	**优点**

​	•	可以发现任意形状的簇；对噪音与离群点不敏感。

​	•	不需要预先指定簇的数量 。

​	4.	**缺点**

​	•	对参数  和  较敏感；高维数据场景中效果不一定理想。



以下给出简要答案要点，供参考整理：



**1. 人工智能的三大学派是什么？它们的主要观点是什么？**



在早期和中期的人工智能研究中，一般将 AI 分为以下三大学派（也有其他分类方式，这里给出主流的一种）：

​	1.	**符号主义（Symbolism / 逻辑主义 / 早期“GOFAI”）**

​	•	**主要观点**：用符号来表示知识和推理规则，模拟人类基于逻辑和推理进行问题求解的过程。强调知识表示、逻辑演绎、专家系统等。

​	2.	**连接主义（Connectionism / 神经网络派）**

​	•	**主要观点**：通过模拟生物神经元网络的结构和学习方式，从大量数据中自动学习复杂的映射关系。认为智能是“大规模分布式并行处理”涌现的结果。

​	3.	**行为主义（Behaviorism / 行为派 / 新兴进化派）**

​	•	**主要观点**：强调智能来源于与环境的直接交互，追求自适应性和进化能力。典型方法包括强化学习、进化算法、行为式机器人等，在对环境做出反应、实时规划方面有优势。



（注：有的资料会将“进化计算、遗传算法”单独作为一派，也有的把“基于统计学习的机器学习”视为另一大派系。不同著作定义略有差异。）



**2. 什么是图搜索过程？重排 open 表意味着什么？**

​	1.	**图搜索过程**

​	•	在人工智能中，很多问题可抽象为“状态空间 + 操作”形成的图（或树），**图搜索**就是在这个状态图/树中寻找从起始状态到目标状态的路径。常见算法有 BFS、DFS、A*、Dijkstra 等。

​	•	在搜索过程中，需要维护一个“已发现但尚未展开的节点列表”（即 **open 表** 或 **frontier**），以及“已访问过的节点列表”（即 **closed 表**）。

​	2.	**重排（或重排/更新）open 表**

​	•	当使用带启发式或代价估计的搜索算法（如 A*、Best-first Search、Dijkstra 等）时，每次有新节点加入到 open 表后，需要根据估值函数（比如 f(n)=g(n)+h(n)）对 open 表进行排序或更新优先级，保证始终先扩展估计最优的节点。

​	•	“重排”就是指在每次插入或更新节点时，对 open 表进行再排序或更新优先队列，以便在下次扩展时能取出优先级最高（估计最优）的节点。



**3. 什么是知识表示？知识表示有哪些要求？**

​	1.	**知识表示（Knowledge Representation）**

​	•	指在计算机中，用某种形式化的方式来描述客观世界中的实体、概念、属性、关系、规则等，以支持自动推理和决策。常见形式包括谓词逻辑、产生式规则、语义网络、框架、知识图谱等。

​	2.	**对知识表示的主要要求**（可概括为以下四个“度”）

​	1.	**表示充分性（Representational Adequacy）**：能表达要解决问题所需的概念和关系，不至于过于受限。

​	2.	**推理有效性（Inferential Adequacy）**：有相应的推理机制，能在已有知识基础上推导出新知识。

​	3.	**获取方便性（Acquisition/ Learning）**：知识的输入或学习过程可行，便于从外部专家或数据中获取。

​	4.	**计算效率（Computational Efficiency）**：在表示和推理过程中，能保持一定的运算效率，避免过于复杂。



**4. 如何缓解 BP 神经网络的过拟合现象？列出三种方法即可**



**过拟合（Overfitting）** 指网络在训练数据上表现非常好，但在测试集或新数据上的泛化能力较差。典型的缓解方法包括（列举三种示例）：

​	1.	**正则化（Regularization）**

​	•	在损失函数中增加 （或 ）正则项，抑制权重过大，让模型更平滑。

​	2.	**早停（Early Stopping）**

​	•	在训练过程中监控验证集误差，当验证集误差开始上升（出现过拟合迹象）时提前停止训练，从而防止模型继续往过拟合方向发展。

​	3.	**数据增强（Data Augmentation）** 或 **增加训练样本**

​	•	对已有数据进行旋转、翻转、加噪等处理，或收集更多多样化的数据，让模型见到更多“不同”样本，从而提升泛化性能。



（其他可选的常见方法还有：**Dropout**（随机失活一部分神经元）、**Batch Normalization**、**降低网络复杂度** 等。）





下面给出针对这 5 个问题的简要回答要点，可根据需要进行扩展或补充示例。



**1. 什么是人工智能？人工智能的主要研究方法有哪些？列举至少三个人工智能目前的热点应用**

​	1.	**人工智能（AI）概念**

​	•	是研究如何让计算机去完成通常需要人类智能才能胜任的任务（如感知、学习、推理、决策等）的科学。其目标是让机器具有类似人类的智能行为。

​	2.	**主要研究方法 / 分支**

​	•	**符号主义（Symbolism）**：用逻辑规则、知识库等符号系统来表示和推理知识，典型如专家系统。

​	•	**连接主义（Connectionism）**：以神经网络为主要模型，强调由大量简单单元的并行分布式处理来“涌现”智能。

​	•	**进化计算 / 行为主义**：通过遗传算法、进化策略或强化学习，让系统与环境交互并逐渐适应、进化。

​	•	（也可提及**统计学习**、**概率图模型**、**贝叶斯网络**等方法。）

​	3.	**AI 的热点应用（示例）**

​	•	**自然语言处理（如大型语言模型、对话机器人）**

​	•	**计算机视觉（人脸识别、目标检测、图像分割）**

​	•	**自动驾驶 / 智能机器人**

​	•	**推荐系统、智能客服、医疗诊断** 等



**2. 什么是启发式搜索？一般估价函数应如何定义？**

​	1.	**启发式搜索（Heuristic Search）**

​	•	在人工智能中，对可能性巨大的搜索空间往往需要“估价”或“启发”来指导搜索，使之更高效地抵达目标。

​	•	常见算法：A*、Best-First Search 等，都基于某种启发式函数（heuristic function）来选择当前最有希望通向目标的节点展开。

​	2.	**估价函数（Heuristic Function）的定义**

​	•	一般记为 ，用于估计从当前节点  到目标节点的“距离”或“代价”。

​	•	在 A* 中，还会用  作为综合评价， 表示从起始节点到  的实际代价， 表示从  到目标的启发式估计。

​	•	设计准则： 需尽可能“乐观不超估”，并与问题本身具有一定领域知识相关性，才能有效指导搜索。



**3. 在数据预处理步骤中，如何处理缺失的数据？如何针对噪声数据进行有效的处理？**

​	1.	**处理缺失数据**

​	•	**删除含缺失值的记录/特征**：仅在缺失比例或重要性较低时使用。

​	•	**插值或填补**：用均值、众数、中位数、插值法或回归模型、KNN 等方式估算缺失值。

​	•	**建立模型进行插补**：例如通过训练一个专门的预测模型来填补缺失值。

​	•	**标记缺失**：引入额外特征标识是否缺失，让模型学习缺失的影响。

​	2.	**处理噪声数据**

​	•	**平滑/滤波**：如移动平均、高斯滤波、离群值检测后平滑处理。

​	•	**去除异常值**：基于统计（3σ原则）、聚类、或其他算法识别极端离群值并剔除。

​	•	**转换或规范化**：对数据做 log / Box-Cox 等变换来减小极端值的影响。

​	•	**重采样或降权**：对噪声较多的数据段可适当降低权重或进行更细粒度的清洗。



**4. 简述 AdaBoost 算法的基本原理**

​	1.	**算法思想**

​	•	**Boosting** 是一种将多个“弱分类器”组合成一个“强分类器”的集成学习方法。

​	•	**AdaBoost（Adaptive Boosting）** 通过迭代训练一系列弱分类器，每一轮会增大对前一轮中被错分样本的关注权重，使得后续弱分类器更“专注”于难分类的样本。

​	2.	**主要步骤**

​	1.	初始化所有训练样本的权重，初始时通常相等。

​	2.	训练一个弱分类器，计算其错误率并更新其投票权。

​	3.	调整样本权重：对被错分的样本提高权重，对正确分类的样本降低权重。

​	4.	重复训练下一个弱分类器，直到达到预设的轮数或误差满足要求。

​	5.	最终分类决策由所有弱分类器的加权投票决定。

​	3.	**优点**

​	•	通常能显著提高分类精度，对过拟合不太敏感。

​	4.	**缺点**

​	•	对噪声数据（特别是错误标注样本）可能比较敏感。



**5. 在机器学习中，举例说明损失函数的作用，列举常见的损失函数**

​	1.	**损失函数的作用**

​	•	度量模型预测值与真实值之间的差距，并指导模型优化参数。

​	•	在训练中，通过最小化损失函数，使模型不断改进预测能力。

​	2.	**常见的损失函数**

​	•	**均方误差（MSE, Mean Squared Error）**

$$\text{MSE} = \frac{1}{N}\sum_{i=1}^N \bigl(\hat{y}_i - y_i\bigr)^2$$

常用于回归问题。对异常值比较敏感。

​	•	**平均绝对误差（MAE, Mean Absolute Error）**

$$\text{MAE} = \frac{1}{N}\sum_{i=1}^N \bigl|\hat{y}_i - y_i\bigr|$$

更少地放大离群点的影响。

​	•	**Hinge Loss**

$$\text{Hinge} = \max\bigl(0, 1 - y_i\hat{y}_i\bigr)$$

SVM 常用的损失，用于最大间隔分类。

​	•	**L1 / L2 正则项** 也可视作损失函数的一部分，用于抑制过拟合。



以上是对题目所列要点的简要回答示例，可结合具体应用场景和算法推导进行更深入的扩展。





![image-20241231004126111](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004126111.png)
![image-20241231004158416](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004158416.png)
![image-20241231004210781](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004210781.png)

![image-20241231004227990](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004227990.png)
![image-20241231004253111](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004253111.png)
![image-20241231004301553](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004301553.png)
![image-20241231004341861](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004341861.png)
![image-20241231004349677](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004349677.png)
![image-20241231004401066](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004401066.png)
![image-20241231004412335](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004412335.png)

![image-20241231004430505](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004430505.png)



![image-20241231004449061](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004449061.png)
![image-20241231004456595](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004456595.png)

![image-20241231004511264](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004511264.png)
![image-20241231004521915](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231004521915.png)





![image-20241231003232995](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231003232995.png)
![image-20241231003306009](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231003306009.png)
![image-20241231003319282](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231003319282.png)
![image-20241231003347320](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231003347320.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/b51cfbcd582a78eb9a97e1d2d12131f4.png)



![img](https://i-blog.csdnimg.cn/blog_migrate/cf1e8bf07b54910db5ff40da02cef5c4.jpeg)



![image-20241231114612412](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231114612412.png)



![image-20241231123652583](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241231123652583.png)





