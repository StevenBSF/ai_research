- 先验知识
- resnet是x+f(x)的方式进行将先验知识进行调整。
- 提示学习是通过冻结backbone参数来进行1%微调
- 大模型的幻觉，我个人认为是因为没有确切的先验知识，即没有冻结正确知识，仅靠概率上猜测判断。
- 能否让模型添加一个约束，使得某些参数就应该调整更多，某些参数学习更少甚至不调整，除非出现某种巨大的惩罚？
