# submission3147

- novelty
  - dual graph interaction (visual and knowledge graphs) and adaptive knowledge bias与现有工作 DRM-net 较为相似，对于双编码理论概念上的阐述和解释并不到位。
  - 论文缺乏与2023年CVPR重要工作（如Prototype-based Embedding Network [35]）的关键比较，而这些方法通过原型学习明确解决了类别间相似性和类别内差异问题。同样，诸如KERN [17]或Bridging Knowledge Graphs [19]等知识增强的SGG方法也未被充分对比，导致所提双轨迹图的创新边界模糊不清。

​	1.Ambiguity in Imagen Generation (Equation 2):The function T(v) , which transforms visual features v into the “Imagen space,” is not explicitly defined. This omission raises concerns about reproducibility and masks potential design flaws. Without clarifying whether T(v) is a linear projection, an attention mechanism, or another operation, the claimed stability of Imagen features remains unverified. Furthermore, if T(v) is not carefully designed, the Hadamard product in Equation 2 could inadvertently amplify noise, leading to unstable feature representations.

​	2.Unjustified Multi-Similarity Loss (Equation 7):The hyperparameters \alpha, \beta, \lambda in the multi-similarity loss lack theoretical grounding. The paper does not explain how these values were selected or their impact on training dynamics. Arbitrary parameter choices may lead to unstable training behaviors, such as gradient explosion or vanishing. Additionally, the logarithmic terms in the loss function could cause imbalanced optimization, particularly if \alpha and \beta are not appropriately tuned. Without ablation studies or theoretical justification, the optimization process remains questionable.

​	3.Unaddressed Noise in Knowledge Graphs:The knowledge graph G_k is constructed using external resources like ConceptNet, yet the paper does not address the potential noise within these sources, such as redundant or incorrect predicates. This omission is problematic because noisy knowledge integration may propagate errors into the dual trace graph, particularly during message passing (Equations 12–15). For instance, irrelevant predicates associated with \hat{r}_{ij} could distort relationship predictions, leading to degraded model performance. Additionally, no ablation studies evaluate the model’s robustness under noisy conditions, making it unclear how effectively the approach handles unreliable external knowledge.



- 实验结果的篇幅较少。文章使用了

- 数学公式和技术术语较多，对于相关的阐述仍然比较晦涩难懂。主图难以让读者第一时间理解方法思路。

- 1.实验说明较为清晰，易于理解。实验结果以及可视化易于读者阅读。

  2.缺少计算效率、训练稳定性和参数敏感性实验，复现性存疑。

- 本论文提出了Cognition-Inspired Dual Trace Graph Network for Scene Graph Generation方法。认知理论的引入具有一定的新颖性，但是受限于增量式改进，技术创新性有限。文章方法展开较为晦涩难懂，对于方法阐述有待具体形象地展开讲解。总体给出weak reject分数。



# submission 1256

- this paper属于 ICME 关注的计算机视觉和多模态学习领域。本文主要研究多模态对话情感识别任务的多模态数据融合、超图结构建模，具有一定的研究价值。

- 本文主要为增量性工作，而篇幅较长的VA-Driven Contrastive Learning部分创新性不足，与UniVA[10]较为相似。ADHConv的方法创新性仍有值得讨论的空间，在设计上较为直白。

- 公式细节的阐述基本正确，但是对于一些维度的描述仍然不够清晰。

- 1.本文涉及到的超参数较多，但是缺少了相应的参数敏感性实验，导致对于参数的设置、模型泛化能力存疑。
  2.数据集较少。希望能有更多的数据集增强说服力。

- 1.主图十分清晰，易于理解。

  2.总体方法流程的阐述较为清晰。

- 1.对于最新的主流方法都有涵盖，如UniVA、HAUCL。

  2.对比方法明确，在实验部分有相应的实验对比。

- 本文提出了ADH-VA框架，实现了多模态情感识别。总体上来看，本文属于增量性工作，VA-Driven Contrastive Learning与现有工作较为相似，ADHConv的设计较为直白，novelty因此受限。参数敏感性分析缺少。主图清晰易懂。整体而言给出borderline的分数。

# submission 1421

- 尽管引入了self-attention and cross-attention等机制，对于将注意力机制具体运用到Detecting Fake News on Short Video Platforms这个任务上的设计上仍然缺少任务上的针对性。方法过于直白俗套，在已有的多模态任务中已有很多相关工作有相应的transformer架构的特别设计，导致难以吸引眼球。

- 1.公式[2-4]过于累赘多余。实际行文不需要在方法中具体展开介绍transformer架构原理，而需要展开讲述自己针对于任务的transformer架构的具体设计。

  2.文章中提到使用causal mask matrix M，对于transformer架构引入因果机制，但是却缺少对于causal mask matrix可行性的相应的说明。比如，引入的动机是什么？引入之后有什么效果？引入和没有引入的区别是什么？作者在文章中并没有详细展开说明，仅一笔带过。

- 1.实验部分数据集较少，reproducibility存疑。

  2.实验结果在数据集较少的情况下和已有方法相比没有展现出足够的性能上的优越性。

- 文章由于方法设计较为简单，行文易于理解。
- 本文针对于Detecting Fake News on Short Video Platforms这个任务提出了MFSVFND模型
- This paper proposes the **MFSVFND model** for **Detecting Fake News on Short Video Platforms**, but its design lacks **task-specific adaptations**, making it somewhat **generic and unoriginal**. While **self-attention and cross-attention** mechanisms are incorporated, they are applied in a straightforward manner without tailored modifications for the task. The explanation of **transformer fundamentals** (e.g., **Equations [2-4]**) is redundant, whereas a deeper discussion on **task-specific adaptations** would be more valuable. Additionally, the **causal mask matrix M** is introduced without sufficient justification regarding its necessity, effectiveness, and impact on performance. In the experimental section, **the dataset is relatively small**, raising **reproducibility concerns**, and the model does not demonstrate a significant **performance advantage** over existing methods, making its contributions **incremental**.

# 1349

- 本文仅对注意力机制最后一层进行修改，将已有技术进行组合，技术创新存疑。

- 消融实验的设计仍有不足。区域语义模块与视觉原型各自对于模型性能效果的提升存疑。

- **术语不一致**：如“vision embeddings”与“pixel embeddings”未明确区分，易导致混淆。

- 

- 1.整体行文较为清晰。

  2.缺少算法伪代码，对于模型的核心算法流程需要进行相应讲解。

- 引用的工作相对充分，但是部分引用的方法没有在实验部分进行对比。如CLIP-DINOiser [23],应当作为相应的baseline进行对比。