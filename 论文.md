## Abstract

​	Multi-view clustering aims to extract effective semantic information from multiple views to obtain better features for clustering. However, most current methods are limited to capturing semantic features and constructing pseudo-labels to capture clustering information, while neglecting the differences among different views and the further extraction of common semantic features. As a result, for some more challenging task data, the presence of irrelevant information and differences in each view makes it difficult to effectively assess the actual semantic quality of different views, leading to insufficient extraction of the common semantic information across views. To solve the above problems, our goal is to extract causal semantic features and generalize the inputs of different views to obtain content that truly lacks view dependency. The challenge lies in how to handle the inputs, extract causal essential features from different views, and apply them to the task of multi-view clustering. To address this, we propose a novel model named **M**ulti-**S**tage **C**ausal Feature Learning for **M**ulti-**V**iew **C**lustering(MSC-MVC).We introduce a causal content label that enables the alignment of content features from different perspectives, thereby eliminating view dependency,and based on this,we assess view quality based on the composition of content features across different views. Additionally, we perform feature augmentation through Gaussian distribution sampling, using similarity graph constraints to mitigate the impact of differences between views. By leveraging causal content features, we can further construct pseudo-label graphs to supervise clustering information. Extensive experiments on seven datasets are performed to illustrate the effectiveness and efficiency of the proposed model.

## Introduction

在过去几十年里，在机器学习和数据挖掘领域里Multi-View Clustering一直是一项火热并且长期处于关注焦点的任务。而多视角聚类的关键之处在于如何充分利用不同视图的有效语义信息将数据自监督地划分为一些各不相关地组别之中。对此，现阶段的对于多视角聚类这一任务的处理方法大致可以分为：基于non-negative matrix factorization,基于subspace learning, graph-based learning.

在这些方法中，特别是graph-based method虽然能够在较多的数据集上通过计算相似图和引入对比学习的方法来对齐latent representation获得了较为满意的结果，但是对于更深、更本质的层次的特征未能得到很好提取，从而导致了对于某些较难的数据集上出现了相较于其他方法在某些指标上面大幅崩溃的结果。For instance，DealMVC 通过结合对比学习和注意力机制融合不同视图的特征，pull close不同视图下不同样本以期望获得更集中的特征表示，在一些视图差异不大的一些数据集上获得了较好的结果，但是对于在一些视图差异较大的数据集上则出现了难以获得理想结果的情况，这是因为对于不同视图各自特征本身的内容和差异未能得到充分的挖掘，而弱化了模型的泛化能力。

为了解决这个问题，我们创新性地将因果机制引入graph-based multi-view clustering这个任务上，以期能够挖掘representation更为本质的特征并且减弱视图依赖性，从而增强各个视图之间的可解释性(identity)和泛化能力。换句话说，我们通过构建新的模型实现了形式化的、更逐步挖掘有效内容信息而非其他无关信息。解决这个问题的难点仍然在于，如何识别不同视图各自的有效特征并且解决视图依赖性。为了方便问题的描述，我们沿用yon中"content-style"的术语。简单来说，例如对于真实世界的图片视角的金毛犬和卡通风格的图片视角下的贵宾犬，由于这两个样本都有相同的狗这一个品种而可形成簇，因此"狗"可以作为因果推断中的内容，而真实世界与卡通风格、金毛犬和贵宾犬这两个品种则可成为"风格"。先前的其他任务的研究中，CIRL将风格视为无关因素而尽可能地保留内容因素而提升泛化能力。由于任务的不同，我们的研究中发现，对于"风格"中的某些因素仍然可能保留某些聚类信息。以刚才的例子，风格中的金毛犬和贵宾犬这两个品种仍保留一定的聚类信息上的相关性，而我们的模型能保证同时挖掘"content"和"style"中的聚类信息。

Moreover，我们分多阶段（multi-stage）提取特征，并且在causal "content-style"的基础上构建图对比学习网络。

## Related Work

### Graph-based MVC

In recent years，越来越多的学者关注到gragh-based method在MVC中的出色表现。考虑到多视图数据的异构性质，Graph-based方法可以灵活地处理异构信息，通过构建不同视图的图结构来综合考虑不同视图的数据，并且通过图的结构信息增强对于多视图聚类结果的鲁棒性和一致性。其中autoencoder被广泛地使用到图聚类中。更具体而言，对于来自$v$-view地输入数据${X^1,X^2,...,X^v}$，经过encoder层$E^v()$和decoder层$D^v()$​得到重构数据，对应地重构损失为：

### Causal Mechanism

当我们谈论到Causal Mechanism，我们不妨先回顾到machine learning以及Statistical Learning Theory。根据Statistical Learning Theory，我们知道对于目前很多方法都满足Statistical Dependence关系，在统计学习理论之下，统计依赖关系是指两个或多个变量之间存在某种统计上的关联，即一个变量的信息可以用来推测另一个变量的信息，我们形式化的表述为$f:X→Y$。但是随着目前各个领域和任务模型逐渐出现瓶颈，比如对于对于一组数据，模型虽然能识别出鞋码与数学成绩具有统计上的相关性，但事实告诉我们其背后共同作用的潜在因素可能是年龄，换句话说，虽然统计学习理论可以帮助我们找到变量之间的关联，但它并不能解释这些关联背后的因果机制。

而如果从Structural causal models对于这个问题建模，则有对于原本的$X \rightarrow Y$ ,遵循Common Cause Principle，应有$X \leftarrow Z \rightarrow Y$,这是因为我们将潜在因素的影响考虑在内。对于causal representation learning,(Scholkopf et al. 2016; Gresele et al. 2020; von Kugelgen et al. 2021)等人展开了详细的工作;(Liu et al. 2024)受causal inference的启发，将因果机制迁移到Text-Based Person Retrieval这个任务中。而具体到对于MVC这个任务上的建模，我们在后续的Methodology中具体展开。



From the perspective of Structural Causal Models, modeling this problem suggests that for the original relationship $X \rightarrow Y$ , and following the Common Cause Principle, we should instead have $X \leftarrow Z \rightarrow Y$. This is because we take into account the influence of latent factors.For causal representation learning, detailed work has been conducted by scholars such as Schölkopf et al. (2016), Gresele et al. (2020), and von Kügelgen et al. (2021). Inspired by causal inference, Liu et al. (2024) have extended causal mechanisms to the task of Text-Based Person Retrieval. Specifically, for modeling the task of multi-view clustering, we will elaborate further in the subsequent Methodology section.

## methodology

### Stage 1

对于多视角聚类任务而言，很多工作的实验验证了autoencoder对于初步提取不同视角的有效信息和去除冗余信息起到明显作用，因此我们的模型中同样吸取了先前的工作经验，并将其作为我们的第一阶段的特征学习。考虑对于输入数据$\{ X^v \in \mathbb{R}^{N \times D_v} \}^{V}_{v=1}$,我们通过encoder层获得初步特征$H^v = E^v(X^v ; \theta^v)\in \mathbb{R}^{N \times D_v}$，where $\theta^v$记作encoder层参数，并且将初步特征进一步经过decoder层获得重构output$\widetilde{X}^v = D^v(H^v ; \psi^v)\in \mathbb{R}^{N \times D_v}$，where $\psi^v$​​记作decoder层参数。重构损失我们采用Eq(1).

### Stage 2

对于Stage 1所利用的autoencoder提取了preliminary features，具有了一定程度上聚类任务所需要的有效信息，不过保留的噪声仍然很多。特别是对于multi-view clustering，我们如何能够让模型鉴别有效信息？而我们的目的之一是为了让feature更加的identify，为了达到这个目的，我们引入因果推断，即从统计层面的输入到聚类簇之间的统计依赖性$P(H^v,C)$过渡至最小化$P(H^v)$和$P(H^v|C)$之间的差距，即$min \|P(H^v) - P(H^v|C) \|$,where $C$表示聚类簇。

而根据Common Cause Principle，我们对于$H^v$和$C$重新形式化为：

$$H^v = g(Z^v) = g(\delta(c^v,s^v,u^v))$$

$$C = h(Z^v) = h(\zeta(c^v,s^v))$$

In Stage 1, the autoencoder extracts preliminary features that contain some degree of useful information for the clustering task, but a significant amount of noise still remains. This is particularly challenging for multi-view clustering, where it is crucial for the model to discern relevant information. One of our objectives is to enhance the identifiability of features. To achieve this, we introduce causal inference, transitioning from the statistical dependence $P(H^v,C)$ between the input and clustering clusters to minimizing the gap between $P(H^v)$ and $P(H^v|C)$, i.e.,$min \|P(H^v) - P(H^v|C) \|$ , where $C$ denotes the clustering clusters.
