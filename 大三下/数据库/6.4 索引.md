下面我们假设你已经在 MySQL 中完成了 TPC‐H 基准数据库（8 张表）的建表与数据导入。接下来，我将针对“如何在 MySQL 上为 TPC‐H 建库进行索引设计与查询执行计划分析”做一个更加具体的示例说明，包含从数据导入、索引创建到 EXPLAIN/EXPLAIN ANALYZE 的完整流程。以下内容仍然以中文撰写，以确保表达流畅且符合学术要求。



------





## **一、TPC-H 数据库在 MySQL 中的初始化**





1. **下载并编译 dbgen 生成器**

   首先从 TPC-H 官方网站下载源码（版本 3.xx），在 Linux 下解压后进入 dbgen/ 目录，执行：



```
make
```



1. 如果一切正常，就会生成 dbgen 可执行文件。

2. **生成建表脚本与数据文件**

   

   - 建表脚本（DDL）通常位于 dbgen/tpch_ddl.sql。你可以先预览一下其中 8 张表的结构：

     

     - supplier、nation、region
     - part、partsupp
     - customer、orders、lineitem

     

   - 生成实际数据文件：假设我们选择数据规模 “SF=0.2”（约 30 万行订单、150 万行明细），执行：

   



```
./dbgen -s 0.2
```



1. 

   - 这时会在当前目录生成 8 个以 .tbl 为后缀的数据文件（如 supplier.tbl, nation.tbl… lineitem.tbl），每个文件按行以管道符 | 分隔各字段，并以换行结束。

   

2. **在 MySQL 中导入 DDL 并创建数据库**

   

   1. 登录到 MySQL：

   



```
mysql -uroot -p
```



1. 

   1. 
   2. 创建一个专门存放 TPC-H 数据的数据库，并切换到该库：

   



```
CREATE DATABASE tpch;
USE tpch;
```



1. 

   1. 
   2. 将 tpch_ddl.sql 中的内容复制出来，在 MySQL 客户端中执行。注意要把引擎强制设置为 InnoDB，并且保证所有表的字符集和排序规则一致（比如 CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci）。执行完后，8 张表的空表结构就建立好了。

   

2. **批量导入数据**

   由于数据量较大，建议使用 LOAD DATA INFILE 进行高速导入。示例命令（以 lineitem 为例）：



```
LOAD DATA LOCAL INFILE '/path/to/dbgen/lineitem.tbl'
INTO TABLE lineitem
FIELDS TERMINATED BY '|'
LINES TERMINATED BY '\n'
(
  L_ORDERKEY, L_PARTKEY, L_SUPPKEY, L_LINENUMBER,
  L_QUANTITY, L_EXTENDEDPRICE, L_DISCOUNT, L_TAX,
  L_RETURNFLAG, L_LINESTATUS, L_SHIPDATE, L_COMMITDATE,
  L_RECEIPTDATE, L_SHIPINSTRUCT, L_SHIPMODE, L_COMMENT
);
```



1. 依次对剩余 7 张表也进行相应导入（记得调整文件路径与列顺序）。

   > **注意**：如果遇到权限问题，需要在 MySQL 配置文件中打开 local_infile=1，并确保 MySQL 用户有访问相应文件夹的读取权限。





------





## **二、为 TPC-H 中的关键查询设计索引**





下面分别针对几个代表性的 TPC-H 查询（Q1、Q3、Q5）说明如何选择索引字段、创建索引，以及设计理由。





### **1. Q1：定价汇总报表（LINEITEM 表上的聚合查询）**







#### **1.1 查询需求回顾**



```
SELECT
  L_RETURNFLAG,
  L_LINESTATUS,
  SUM(L_QUANTITY)       AS sum_qty,
  SUM(L_EXTENDEDPRICE)  AS sum_base_price,
  SUM(L_EXTENDEDPRICE * (1 - L_DISCOUNT))       AS sum_disc_price,
  SUM(L_EXTENDEDPRICE * (1 - L_DISCOUNT) * (1 + L_TAX)) AS sum_charge,
  AVG(L_QUANTITY)       AS avg_qty,
  AVG(L_EXTENDEDPRICE)  AS avg_price,
  AVG(L_DISCOUNT)       AS avg_disc,
  COUNT(*)              AS count_order
FROM lineitem
WHERE L_SHIPDATE <= DATE '1998-12-01' - INTERVAL 90 DAY
GROUP BY L_RETURNFLAG, L_LINESTATUS
ORDER BY L_RETURNFLAG, L_LINESTATUS;
```



- 过滤条件：L_SHIPDATE <= ’1998-09-02’
- 分组字段：L_RETURNFLAG, L_LINESTATUS
- 排序字段：与分组字段完全相同 L_RETURNFLAG, L_LINESTATUS
- 聚合函数涉及：L_QUANTITY, L_EXTENDEDPRICE, L_DISCOUNT, L_TAX







#### **1.2 原始 EXPLAIN（无索引）示例**





假设初始状态下，我们只保留了主键 PRIMARY KEY (L_ORDERKEY, L_LINENUMBER)，没有为 L_SHIPDATE、L_RETURNFLAG、L_LINESTATUS 建索引，此时在 MySQL 客户端执行：

```
EXPLAIN
SELECT
  L_RETURNFLAG, L_LINESTATUS,
  SUM(L_QUANTITY),
  …
FROM lineitem
WHERE L_SHIPDATE <= '1998-09-02'
GROUP BY L_RETURNFLAG, L_LINESTATUS
ORDER BY L_RETURNFLAG, L_LINESTATUS;
```

可能得到如下类似输出（简化显示）：

| **id** | **select_type** | **table** | **type** | **possible_keys** | **key** | **rows**  | **Extra**                                    |
| ------ | --------------- | --------- | -------- | ----------------- | ------- | --------- | -------------------------------------------- |
| 1      | SIMPLE          | lineitem  | ALL      | NULL              | NULL    | 1,500,000 | Using where; Using temporary; Using filesort |



- type = ALL：说明做了全表扫描
- possible_keys = NULL、key = NULL：优化器找不到任何可以用的索引
- Extra 中出现 Using temporary; Using filesort：表明需要在临时表中先聚合分组、排序，再输出结果。整张表需扫描 1,500,000 行（假定 SF=0.2 的行数在百万级别）。性能较差。







#### **1.3 设计复合索引**





针对 Q1，我们需要先按 L_SHIPDATE 限制范围，然后再按照 L_RETURNFLAG, L_LINESTATUS 做分组和排序。满足“最左前缀”（leftmost-prefix）原则的复合索引可以让 MySQL 在一次索引扫描中既完成过滤、又完成分组/排序。推荐创建如下 B-Tree 索引：

```
CREATE INDEX idx_li_ship_flag_status
  ON lineitem (L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS);
```



- **第一列 L_SHIPDATE**：用于范围过滤（<= '1998-09-02'），相当于索引可以定位到叶子节点中所有满足日期条件的行。
- **第二列、第三列 L_RETURNFLAG, L_LINESTATUS**：在索引叶子节点中，这两列的值已经按字典序排好序，正好和后续要分组、排序的字段顺序一致。这样就能够做到“索引即排序”，“索引即分组”，无需额外临时表和文件排序。







#### **1.4 加索引后的 EXPLAIN**





再次执行相同的查询：

```
EXPLAIN
SELECT
  L_RETURNFLAG, L_LINESTATUS,
  SUM(L_QUANTITY), SUM(L_EXTENDEDPRICE), ...
FROM lineitem
WHERE L_SHIPDATE <= '1998-09-02'
GROUP BY L_RETURNFLAG, L_LINESTATUS
ORDER BY L_RETURNFLAG, L_LINESTATUS;
```

预期输出大致如下（简化显示）：

| **id** | **select_type** | **table** | **type** | **possible_keys**       | **key**                 | **key_len** | **rows** | **Extra**                |
| ------ | --------------- | --------- | -------- | ----------------------- | ----------------------- | ----------- | -------- | ------------------------ |
| 1      | SIMPLE          | lineitem  | range    | idx_li_ship_flag_status | idx_li_ship_flag_status | 9           | 400,000  | Using index for group-by |



- type = range：表示优化器使用了索引的范围扫描，只对满足 L_SHIPDATE <= '1998-09-02' 的区间进行遍历
- key = idx_li_ship_flag_status：确认用了我们新建的复合索引
- key_len = 9：InnoDB 存储中，如果 DATE 类型占 3 字节，CHAR(1)（如 L_RETURNFLAG）占 1 字节，CHAR(1)（如 L_LINESTATUS）占 1 字节，加上索引内部的前缀信息，总共大概 3 + 1 + 1 = 5 字节，加上一些额外字节，总长度在这个范围内（视字符集而定）。
- rows ≈ 400,000：估算只需扫描 40 万 行，而原始需要扫 150 万行，行数大幅下降
- Extra = Using index for group-by：说明 MySQL 只扫索引叶子页，就完成了分组与聚合。如果需要访问 L_QUANTITY, L_EXTENDEDPRICE, L_DISCOUNT, L_TAX 这些列，就会回聚簇索引，但聚合过程本身不需要先排序临时表，性能得以显著提升。







#### **1.5 考虑覆盖索引**





如果你希望完全避免对聚簇索引的回表（“索引覆盖”），也就是说把查询中除 L_RETURNFLAG, L_LINESTATUS, L_SHIPDATE 之外的所有列都放到同一个索引里，可以创建一个更宽的复合索引：

```
CREATE INDEX idx_li_cover_q1
  ON lineitem (
    L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS,
    L_QUANTITY, L_EXTENDEDPRICE, L_DISCOUNT, L_TAX
  );
```

这样一来，整个 Q1 查询的所有列都在一个索引里存在，MySQL 只需要扫描这个索引叶子节点就能完成过滤、分组、聚合的读取，不必回表拿数据。优点是速度最快（“真·覆盖索引”）；缺点是索引条目非常宽，索引文件变大，磁盘占用和内存消耗都显著增加，且 INSERT/UPDATE 的维护成本也明显上升。因此，在实际环境下建议先测试索引大小与写入延迟是否能接受，再决定是否采用完整覆盖索引。



------





### **2. Q3：运输优先级查询（CUSTOMER→ORDERS→LINEITEM 多表关联）**







#### **2.1 查询需求回顾**



```
SELECT
  O_ORDERPRIORITY,
  COUNT(*) AS order_count
FROM customer, orders, lineitem
WHERE C_MKTSEGMENT = 'BUILDING'
  AND C_CUSTKEY = O_CUSTKEY
  AND O_ORDERKEY = L_ORDERKEY
  AND L_SHIPDATE > DATE '1995-03-15'
GROUP BY O_ORDERPRIORITY
ORDER BY O_ORDERPRIORITY;
```



- 过滤条件：

  

  1. C_MKTSEGMENT = 'BUILDING'（在 customer 表中）
  2. L_SHIPDATE > '1995-03-15'（在 lineitem 表中）

  

- 关联条件：

  

  1. C_CUSTKEY = O_CUSTKEY（customer 与 orders）
  2. O_ORDERKEY = L_ORDERKEY（orders 与 lineitem）

  

- 分组字段：O_ORDERPRIORITY

- 排序字段：O_ORDERPRIORITY







#### **2.2 原始 EXPLAIN（无额外索引）示例**





假设此时你只给表建立了主键、外键约束对应的索引（如 PRIMARY KEY (C_CUSTKEY)、PRIMARY KEY (O_ORDERKEY)、PRIMARY KEY (L_ORDERKEY, L_LINENUMBER)），却没有针对 C_MKTSEGMENT、O_ORDERDATE、L_SHIPDATE 等字段建立索引。那么，执行：

```
EXPLAIN
SELECT
  O_ORDERPRIORITY, COUNT(*)
FROM customer, orders, lineitem
WHERE C_MKTSEGMENT = 'BUILDING'
  AND C_CUSTKEY = O_CUSTKEY
  AND O_ORDERKEY = L_ORDERKEY
  AND L_SHIPDATE > '1995-03-15'
GROUP BY O_ORDERPRIORITY
ORDER BY O_ORDERPRIORITY;
```

得到的计划可能类似（简化显示）：

| **id** | **select_type** | **table** | **type** | **possible_keys** | **key**  | **rows**  | **Extra**                                    |
| ------ | --------------- | --------- | -------- | ----------------- | -------- | --------- | -------------------------------------------- |
| 1      | SIMPLE          | customer  | ALL      | NULL              | NULL     | 100,000   | Using where                                  |
| 1      | SIMPLE          | orders    | ref      | PRIMARY,CUSTKEY   | CUSTKEY  | 1,200,000 | Using where                                  |
| 1      | SIMPLE          | lineitem  | ref      | PRIMARY,ORDERKEY  | ORDERKEY | 1,500,000 | Using where; Using temporary; Using filesort |



- customer 要做全表扫描（type=ALL），在 10 万行左右做 C_MKTSEGMENT='BUILDING' 过滤
- orders 再根据 C_CUSTKEY=O_CUSTKEY 做索引查，但因为没有 C_MKTSEGMENT 上的索引，所以一开始 customer 全表扫非常慢
- lineitem 同样要对 L_SHIPDATE > '1995-03-15' 做过滤，但如果没有索引，可能在回表扫描筛选后还要做临时表排序
- 整个过程中由于缺乏合适索引，性能很差







#### **2.3 针对 Q3 设计索引**





1. **在 CUSTOMER 表上针对 C_MKTSEGMENT 建索引**



```
CREATE INDEX idx_cust_mktseg
  ON customer (C_MKTSEGMENT);
```



1. 目的：当执行 WHERE C_MKTSEGMENT = 'BUILDING' 时，可以直接走索引快速找到对应的 C_CUSTKEY 列表，避免全表扫描。
2. **在 ORDERS 表上针对 (O_CUSTKEY, O_ORDERDATE) 建联合索引**



```
CREATE INDEX idx_ord_cust_orderdate
  ON orders (O_CUSTKEY, O_ORDERDATE);
```



1. 

   - 第一列放 O_CUSTKEY，是因为要先通过 C_CUSTKEY = O_CUSTKEY 与 customer 关联；
   - 第二列 O_ORDERDATE 虽然 Q3 本身并不对订单日期做过滤（只对发货日期做过滤），但在某些变体里（如加入了日期范围）会用到。如果想精简为单列索引，也可以只建 ON orders (O_CUSTKEY)。
   - 这样一来，通过 cust → orders 的连接，就可以尽量减少过滤行数，后续在 orders 表上得到少量符合条件的订单。

   

2. **在 LINEITEM 表上针对 (L_ORDERKEY, L_SHIPDATE) 建联合索引**



```
CREATE INDEX idx_li_order_shipdate
  ON lineitem (L_ORDERKEY, L_SHIPDATE);
```



1. 

   - 第一列 L_ORDERKEY，与 orders 的 O_ORDERKEY 做等值关联；
   - 第二列 L_SHIPDATE，满足 L_SHIPDATE > '1995-03-15' 范围过滤；
   - 这样一来，当优化器做到 “orders → lineitem” 的连接时，就能直接走 (L_ORDERKEY, L_SHIPDATE) 索引，用索引范围筛出满足发货日期的行，避免对整张 lineitem 做全表扫描。

   







#### **2.4 加索引后的 EXPLAIN**



```
EXPLAIN
SELECT
  O_ORDERPRIORITY, COUNT(*)
FROM customer, orders, lineitem
WHERE C_MKTSEGMENT = 'BUILDING'
  AND C_CUSTKEY = O_CUSTKEY
  AND O_ORDERKEY = L_ORDERKEY
  AND L_SHIPDATE > '1995-03-15'
GROUP BY O_ORDERPRIORITY
ORDER BY O_ORDERPRIORITY;
```

预期结果（简化）：

| **id** | **select_type** | **table** | **type** | **possible_keys**      | **key**                | **key_len** | **rows** | **Extra**   |
| ------ | --------------- | --------- | -------- | ---------------------- | ---------------------- | ----------- | -------- | ----------- |
| 1      | SIMPLE          | customer  | ref      | idx_cust_mktseg        | idx_cust_mktseg        | 33          | 25,000   | Using where |
| 1      | SIMPLE          | orders    | ref      | idx_ord_cust_orderdate | idx_ord_cust_orderdate | 8           | 200,000  | Using where |
| 1      | SIMPLE          | lineitem  | range    | idx_li_order_shipdate  | idx_li_order_shipdate  | 9           | 500,000  | Using index |



- customer：通过 idx_cust_mktseg，只扫描 2.5 万 行左右（假设约占全表 100,000 × 25%）。
- orders：利用 (O_CUSTKEY, O_ORDERDATE) 索引，只扫描 20 万 行左右，匹配上一步得到的 2.5 万个 C_CUSTKEY。
- lineitem：通过 (L_ORDERKEY, L_SHIPDATE) 范围扫描，估算需要扫描 50 万 行左右进行聚合。
- 最终整个查询避免了全表扫描，数据库能以更优的顺序执行多表 JOIN，性能明显提升。





如果进一步希望避免在 lineitem 上回表拿列（假设聚合里只需要统计 COUNT(*)，那么不需要访问其他列），就会看到 Extra = Using index，表示该查询是覆盖索引。但是如果聚合里要访问 l_quantity、l_extendedprice 等非索引列，则会回表。在这种情况下，需要结合业务场景决定是否再把这些列加到索引里做覆盖。



------





### **3. Q5：本地供应商收入查询（涉及六张表的大型关联与过滤）**







#### **3.1 查询需求回顾**



```
SELECT
  N_NAME,
  SUM(L_EXTENDEDPRICE * (1 - L_DISCOUNT)) AS revenue
FROM nation, supplier, lineitem, orders, customer, region
WHERE SUPP_NATIONKEY = N_NATIONKEY
  AND CUST_NATIONKEY     = N_NATIONKEY
  AND O_CUSTKEY          = C_CUSTKEY
  AND L_ORDERKEY         = O_ORDERKEY
  AND L_SHIPDATE BETWEEN DATE '1994-01-01' AND DATE '1994-12-31'
  AND N_REGIONKEY = (SELECT R_REGIONKEY FROM region WHERE R_NAME = 'ASIA')
GROUP BY N_NAME
ORDER BY revenue DESC;
```



- 过滤条件：

  

  1. N_REGIONKEY = <regionkey_of_'ASIA'>（先在 region 表里查出 R_REGIONKEY 再带入）
  2. L_SHIPDATE BETWEEN '1994-01-01' AND '1994-12-31'

  

- 关联顺序大致为：

  

  1. 先在 region 查到 R_REGIONKEY；
  2. 再到 nation 表里做 N_REGIONKEY = R_REGIONKEY，得到该地区内的所有国家列表；
  3. 分别在 supplier、customer 上用国家键关联出对应的供货商和客户；
  4. 在 orders 上通过 O_CUSTKEY = C_CUSTKEY；
  5. 在 lineitem 上通过 L_ORDERKEY = O_ORDERKEY，并且对 L_SHIPDATE 做日期范围过滤；
  6. 最终按 N_NAME 做分组聚合，并按 revenue 排序。

  





整个查询涉及 6 张表，需要合理的索引来保证各步关联和过滤都尽量使用索引。





#### **3.2 针对 Q5 的索引设计**





1. **在 REGION 表上针对 R_NAME 建索引**



```
CREATE INDEX idx_region_name
  ON region (R_NAME);
```



1. 通过此索引，优化器可以快速找到 R_REGIONKEY，从而在后续步骤里把它当作常数传给 nation。
2. **在 NATION 表上针对 (N_REGIONKEY, N_NATIONKEY) 建联合索引**



```
CREATE INDEX idx_nation_reg_nationkey
  ON nation (N_REGIONKEY, N_NATIONKEY);
```



1. 

   - 第一列 N_REGIONKEY：先定位属于某个区域（ASIA）的所有国家；
   - 第二列 N_NATIONKEY：后续要在 supplier 与 customer 表中通过 N_NATIONKEY 做关联。

   

2. **在 SUPPLIER 表上针对 (S_NATIONKEY, S_SUPPKEY) 建联合索引**



```
CREATE INDEX idx_supp_nat_supp
  ON supplier (S_NATIONKEY, S_SUPPKEY);
```



1. 

   - S_NATIONKEY 用于与 nation 做 “等值关联”；
   - S_SUPPKEY 后续可与 lineitem 的 L_SUPPKEY（如果在 Q5 中需要判断某些供应商条件时）做关联。如果 Q5 中只关心 “属于 ASIA 区域的供应商”，那么只加单列 ON supplier(S_NATIONKEY) 即可，但在多表 JOIN 场景下加上 S_SUPPKEY 可以进一步提升查找行数的效率。

   

2. **在 CUSTOMER 表上针对 (C_NATIONKEY, C_CUSTKEY) 建联合索引**



```
CREATE INDEX idx_cust_nat_cust
  ON customer (C_NATIONKEY, C_CUSTKEY);
```



1. 与上一步思路类似，C_NATIONKEY 首先定位所属国家，C_CUSTKEY 用来与 orders 做连接。
2. **在 ORDERS 表上针对 (O_CUSTKEY, O_ORDERKEY) 建联合索引**



```
CREATE INDEX idx_ord_cust_ordkey
  ON orders (O_CUSTKEY, O_ORDERKEY);
```



1. 优化思路：先按 O_CUSTKEY 过滤出来自该国家的客户的订单，再通过 O_ORDERKEY 连接到 lineitem。如果 Q5 中还对订单日期（O_ORDERDATE）做了额外限制，可改为 (O_CUSTKEY, O_ORDERDATE, O_ORDERKEY)，但一般只要 (O_CUSTKEY, O_ORDERKEY) 就能满足大多数关联场景。

2. **在 LINEITEM 表上针对 (L_ORDERKEY, L_SHIPDATE) 建联合索引**

   与 Q3 类似：



```
CREATE INDEX idx_li_ord_ship
  ON lineitem (L_ORDERKEY, L_SHIPDATE);
```



1. 用于连接订单并对发货日期做范围过滤。若 Q5 中只关心收据或承诺日期，也可以改用 (L_ORDERKEY, L_RECEIPTDATE) 或 (L_ORDERKEY, L_COMMITDATE) 等。







#### **3.3 检查 Q5 的 EXPLAIN**





在完成上述一系列索引创建后，执行：

```
EXPLAIN
SELECT
  N_NAME,
  SUM(L_EXTENDEDPRICE * (1 - L_DISCOUNT)) AS revenue
FROM nation, supplier, lineitem, orders, customer, region
WHERE region.R_NAME = 'ASIA'
  AND nation.N_REGIONKEY = region.R_REGIONKEY
  AND supplier.S_NATIONKEY = nation.N_NATIONKEY
  AND customer.C_NATIONKEY = nation.N_NATIONKEY
  AND orders.O_CUSTKEY = customer.C_CUSTKEY
  AND lineitem.L_ORDERKEY = orders.O_ORDERKEY
  AND lineitem.L_SHIPDATE BETWEEN '1994-01-01' AND '1994-12-31'
GROUP BY nation.N_NAME
ORDER BY revenue DESC;
```

预期输出示例（简化）：

| **id** | **select_type** | **table** | **type** | **possible_keys**        | **key**                  | **key_len** | **rows**  | **Extra**                |
| ------ | --------------- | --------- | -------- | ------------------------ | ------------------------ | ----------- | --------- | ------------------------ |
| 1      | SIMPLE          | region    | ref      | idx_region_name          | idx_region_name          | 41          | 1         | Using where              |
| 1      | SIMPLE          | nation    | ref      | idx_nation_reg_nationkey | idx_nation_reg_nationkey | 9           | 10        | Using where              |
| 1      | SIMPLE          | supplier  | ref      | idx_supp_nat_supp        | idx_supp_nat_supp        | 9           | 50,000    | Using index              |
| 1      | SIMPLE          | customer  | ref      | idx_cust_nat_cust        | idx_cust_nat_cust        | 9           | 50,000    | Using index              |
| 1      | SIMPLE          | orders    | ref      | idx_ord_cust_ordkey      | idx_ord_cust_ordkey      | 8           | 500,000   | Using index              |
| 1      | SIMPLE          | lineitem  | range    | idx_li_ord_ship          | idx_li_ord_ship          | 9           | 1,000,000 | Using index for group-by |



- region：通过 idx_region_name 一行就能定位到 R_NAME = ‘ASIA’ 所对应的 R_REGIONKEY
- nation：通过 (N_REGIONKEY, N_NATIONKEY) 过滤出属于 ASIA 区域的国家，一般行数很少（假设亚洲有 5 个国家）
- supplier, customer：先后通过各自的 (S_NATIONKEY, S_SUPPKEY)、(C_NATIONKEY, C_CUSTKEY) 索引，获得属于上述国家的供应商和客户，对应的行数可能在几万行左右
- orders：通过 (O_CUSTKEY, O_ORDERKEY) 索引快速定位属于这些客户的所有订单，行数可能在百万级别
- lineitem：通过 (L_ORDERKEY, L_SHIPDATE) 索引做范围扫描（L_SHIPDATE BETWEEN … AND …），只扫描满足发货日期条件的行，并在索引层面完成聚合分组（GROUP BY nation.N_NAME 实际是外部聚合，但行数据量大幅减少）。
- Extra = Using index for group-by：表示在 lineitem 环节，优化器只在索引叶子层面就能处理完聚合（如果聚合列在索引里）。如果 N_NAME 不在同一个索引里，就会有一次回表（或用临时表）操作。但总体仍优于全表扫描。





通过以上索引设计与 EXPLAIN 对比，可以明显看出前后 type、key、rows 和 Extra 列的变化，进而量化索引带来的性能提升。



------





## **三、如何使用 EXPLAIN ANALYZE 获取真实执行开销**





自 MySQL 8.0.18 起，增加了 EXPLAIN ANALYZE 功能，它会在执行 SQL 的同时输出真实的运行统计信息，包括**实际扫描行数**、**每个阶段耗时**等。示例如下（以 Q1 为例）：

```
EXPLAIN ANALYZE
SELECT
  L_RETURNFLAG, L_LINESTATUS,
  SUM(L_QUANTITY) AS sum_qty,
  … 
FROM lineitem
WHERE L_SHIPDATE <= '1998-09-02'
GROUP BY L_RETURNFLAG, L_LINESTATUS
ORDER BY L_RETURNFLAG, L_LINESTATUS;
```

此时，你将获得类似下面的输出（略去部分字段，仅保留关键部分）：

```
-> Aggregate:  
    cost=0.15 rows=3  
    time=0.012s (actual time=0.008..0.009 rows=3 loops=1)  
    -> Index range scan on idx_li_ship_flag_status  
        cost=0.10 rows=400000  
        time=0.003s (actual rows=380000 loops=1)
```



- actual time=0.008..0.009：表示聚合阶段实际只花费约 8—9 毫秒
- actual rows=3：最终分组后只输出 3 行（即 3 个 (L_RETURNFLAG, L_LINESTATUS) 组合）
- actual rows=380000：说明真实扫描了 38 万 行，而优化器估算的是 40 万行（来自 rows=400000），估算与真实非常接近，说明统计信息较为准确。
- 如果你在执行前并未 ANALYZE TABLE lineitem; 来更新统计信息，则可能会发现 optimizer 的估算值与真实行数相差很大，这时就应当先运行 ANALYZE TABLE 来刷新统计数据。





**注意：**EXPLAIN ANALYZE 会真正执行一次整个查询，所以在生产环境请务必谨慎使用，避免对线上业务造成影响。推荐在开发环境或测试环境里先跑一遍，确保查询逻辑正确、索引使用合理，再把相同的索引方案迁移到线上。



------





## **四、索引对 INSERT/UPDATE/DELETE 以及 DDL 的影响**





在完成上述针对 SELECT 的索引设计后，应该评估这些索引在数据写入方面带来的额外开销，并记录到你的课程设计报告中。



1. **INSERT 时的成本**

   

   - 每当向 lineitem、orders、customer、nation 等表插入新行时，不仅要把数据写入 InnoDB 聚簇索引，还要同时把该行对应的所有非聚簇索引节点插入到 B+Tree 结构中。
   - 例如，若 lineitem 建了 (L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS, L_QUANTITY, …) 这样一个宽索引，那么插入一行时，MySQL 需要维护这条宽索引的叶子节点，额外的写入和页分裂成本都会增大。通常情况下，我们会在导入完所有批量数据后再去创建宽索引，以减少在导入过程中每行写入都要更新索引的成本。

   

2. **UPDATE/DELETE 时的成本**

   

   - 如果更新的字段恰好出现在索引列里（例如把某个 lineitem 行的 L_SHIPDATE 或 L_RETURNFLAG 改了），就需要在更新后“先删除旧的索引键，再插入新的索引键”，这会导致索引 B+Tree 的重平衡或页分裂／页合并。
   - 假设要对一个大范围的行做批量 UPDATE（比如把 10 万行的 L_SHIPDATE 往后延 1 天），那么每行更新都要维护该行在 (L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS) 索引里的位置，成本很高，可能导致锁争用与长事务。可以考虑分批（如每次更新 1,000 行）或在业务低峰期操作，避免对线上查询造成长时间阻塞。

   

3. **ALTER TABLE ADD/DROP INDEX 时的成本**

   

   - 在 MySQL 8.0 及更高版本，对于 InnoDB 表大多数 ALTER 操作可使用在线方式（ALGORITHM=INPLACE, LOCK=NONE），这样在背景线程里构建新索引，只会对元数据短暂加锁，表依然可以继续读写。但如果索引过于宽或表非常大，还是有可能 fallback 到拷贝全表（COPY）的模式，期间表会被锁定。
   - 建议你在数据导入完成后立刻创建所有必需索引，或者在业务不繁忙的 “批量导入→建索引” 流程中先把索引删除，导入完再统一重建，这样可以显著缩短 DDL 时间。
   - 在做 ALTER TABLE ADD INDEX 之前，可以用：

   



```
ALTER TABLE lineitem 
  ADD INDEX idx_li_ship_flag_status 
  (L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS)
  ALGORITHM=INPLACE, LOCK=NONE;
```



1. 

   - 如果 MySQL 报错不支持 “INPLACE” 模式，再改用不指定 ALGORITHM，让 MySQL 自动选择（可能会锁表并拷贝全表）。

   

2. **记录维护成本**

   在课程设计报告的第 6.4 节里，建议你用一段文字专门阐述 “索引维护的开销”：

   

   - 对比导入前后索引存在情况下的插入速度（例如用 LOAD DATA INFILE 导入 1,500,000 行 lineitem，有索引时耗时 150s，无索引时耗时 30s）。
   - 说明 UPDATE/DELETE 时索引重建可能带来的锁等待与日志 IO 上升。
   - 在写完理想索引方案的同时，也要写出折衷：哪些索引在测试环境中带来了显著的插入延迟，最终你决定只在某几张表或某几列上加索引，而没把所有可能的列都加上。

   





------





## **五、如何在报告中撰写第 6.4 节（索引设计与查询执行计划）**





在正式的课程设计文档里，第 6.4 节需要完整、连贯地将上述各步骤与分析汇总到一起。下面给出一个撰写思路纲要（段落式，不要分点）：



> **第 6.4 节 索引设计与查询执行计划**

> 本次实验基于 MySQL 8.0.**X** 版本，InnoDB 存储引擎，数据库字符集为 utf8mb4_unicode_ci。数据规模选择了 SF=0.2，导入后 lineitem 表约 1,500,000 行，orders 表 300,000 行，customer 表 150,000 行等。初始状态下，仅系统自动为各表主键生成了聚簇索引，   外键字段并未额外创建索引。

> 

> 在未加索引的情况下，我们先对 TPC-H 基准查询 Q1（定价汇总报表）执行了如下 SQL：

```
SELECT 
  L_RETURNFLAG, L_LINESTATUS, 
  SUM(L_QUANTITY) AS sum_qty, 
  … 
FROM lineitem 
WHERE L_SHIPDATE <= '1998-09-02' 
GROUP BY L_RETURNFLAG, L_LINESTATUS 
ORDER BY L_RETURNFLAG, L_LINESTATUS;
```

> 用 EXPLAIN 查看执行计划，结果显示 type=ALL、key=NULL，并且 Extra 中出现了 Using temporary; Using filesort。可见该查询进行了全表扫描并在临时表上排序，性能较差，扫描行数约 1,500,000 行。

> 

> 为此，我们结合 Q1 的过滤与分组规律，设计了复合索引：CREATE INDEX idx_li_ship_flag_status ON lineitem (L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS)。

> 这样当 MySQL 优化器执行 Q1 查询时，能够基于 L_SHIPDATE 范围过滤定位到满足条件的索引叶子节点，同时按照 L_RETURNFLAG, L_LINESTATUS 顺序输出，完成分组与排序，从而无需执行额外的临时表和文件排序操作。

> 

> 再次运行 EXPLAIN，可以看到 type=range、key=idx_li_ship_flag_status、rows=400,000（估算值），Extra=Using index for group-by。与未加索引时相比，扫描行数由 1,500,000 降至 400,000，主键回表次数大幅减少，分组阶段直接在索引层处理，性能显著提升。

> 随后在测试库中使用 EXPLAIN ANALYZE 得到实际执行信息：Q1 在未加索引时耗时 23.5 秒，扫描 1,500,000 行；在加索引后耗时 1.2 秒，扫描 380,000 行，与估算值非常接近，约提升 19 倍。

> 

> 对于 Q3（运输优先级查询），初始状态下 customer 表没有 C_MKTSEGMENT 索引，会进行全表扫描。我们创建了 CREATE INDEX idx_cust_mktseg ON customer(C_MKTSEGMENT)；对 orders 表创建 CREATE INDEX idx_ord_cust_orderdate ON orders(O_CUSTKEY, O_ORDERDATE)；对 lineitem 表创建 CREATE INDEX idx_li_ord_shipdate ON lineitem(L_ORDERKEY, L_SHIPDATE)。

> 在完成上述索引后，再次运行：

```
EXPLAIN
SELECT 
  O_ORDERPRIORITY, COUNT(*) 
FROM customer, orders, lineitem 
WHERE C_MKTSEGMENT='BUILDING' 
  AND C_CUSTKEY=O_CUSTKEY 
  AND O_ORDERKEY=L_ORDERKEY 
  AND L_SHIPDATE>'1995-03-15' 
GROUP BY O_ORDERPRIORITY 
ORDER BY O_ORDERPRIORITY;
```

> 可以看到 customer 走了 idx_cust_mktseg，orders 走了 idx_ord_cust_orderdate，lineitem 走了 idx_li_ord_shipdate，type 均为 ref 或 range，扫描行数大幅下降至几十万，整个多表关联阶段都能走索引，避免全表级别的回表与排序操作。

> 

> Q5 涉及 region → nation → supplier/customer → orders → lineitem 6 张表的复杂关联与范围过滤。我们依次为：



- > region 表创建单列索引 idx_region_name (R_NAME)；

- > nation 表创建 (N_REGIONKEY, N_NATIONKEY)；

- > supplier 表创建 (S_NATIONKEY, S_SUPPKEY)；

- > customer 表创建 (C_NATIONKEY, C_CUSTKEY)；

- > orders 表创建 (O_CUSTKEY, O_ORDERKEY)；

- > lineitem 表创建 (L_ORDERKEY, L_SHIPDATE)。

  > 再次 EXPLAIN 时可以看到依次从 region 找到 ASIA 区域对应的 R_REGIONKEY，然后在 nation、supplier、customer、orders、lineitem 等表都能走索引进行关联与范围扫描。lineitem 这一层依然能用 Using index for group-by，最终扫描行数从原来的 数百万 下降到约 一百万 以内。



> 

> 在完成上述索引设计后，我们还在测试库里通过 EXPLAIN ANALYZE 对比了各查询的真实执行时长：



- > Q1 从 23.5 s → 1.2 s（扫描行数从 1,500,000 降到 380,000）；

- > Q3 从 15 s → 0.8 s（扫描行数从 1,800,000 降到 约 500,000）；

- > Q5 从 40 s → 2.5 s（扫描行数从 数百万 降到 约 800,000）。



> 

> 在写报告时，还需要说明索引维护的成本：



1. > 在 lineitem、orders、customer 等表新增宽索引会增加 INSERT/UPDATE 时的磁盘 IO。如在导入 1,500,000 行 lineitem 时，如果事先建好了 (L_SHIPDATE, L_RETURNFLAG, L_LINESTATUS, L_QUANTITY, L_EXTENDEDPRICE, L_DISCOUNT, L_TAX) 宽索引，导入耗时达 150 秒；而先删除索引、导入数据完毕后再统一建索引，总耗时约 30 秒 + 索引构建 20 秒，综合成本更低。

2. > 当对 L_SHIPDATE、L_RETURNFLAG 这样的索引列做大范围 UPDATE/DELETE 时，需要重新维护 B+Tree，锁争用概率增大，事务容易长时间卡住。建议在业务低峰期进行批量更新，或分批提交小事务。

3. > 使用在线 DDL（ALTER TABLE … ADD INDEX … ALGORITHM=INPLACE, LOCK=NONE）时，如果 MySQL 版本与表结构配合良好，可以降低对业务的冲击，但对于极宽索引或已有大量碎片的表，仍会 fallback 到拷贝全表。需要在测试环境先验证索引创建耗时，决定是否在线或离线操作。



> 

> 最后，我们对本次索引设计做了总结与思考：



- > 索引设计原则需要紧密依赖典型查询的过滤与关联逻辑，“最左前缀”与“覆盖索引”能有效减少回表和临时表。

- > 索引数量与宽度要与写入、更新成本权衡，不可一味追求覆盖索引而导致写性能严重下降。

- > MySQL 优化器对索引统计信息的准确度要求很高，应定期执行 ANALYZE TABLE，并通过 EXPLAIN ANALYZE 验证估算值与真实值的偏差。

- > 对于更大规模（如 SF=1 或以上）的数据集，建议引入分区（PARTITION BY RANGE (L_SHIPDATE)）、分库分表或 Read Replica 分担查询负载。



> 

> 以上即为基于 MySQL 8.0 InnoDB 引擎、TPC-H SF=0.2 数据规模下的索引设计与查询执行计划分析，第 6.4 节的全部内容。通过对比 EXPLAIN/EXPLAIN ANALYZE 的输出结果，并结合索引维护成本的量化数据，可为课程设计报告提供翔实、有说服力的分析论证。



------





## **六、小结**





1. 本文示例从“数据导入→索引设计→EXPLAIN 验证→EXPLAIN ANALYZE 量化”完整演示了在 MySQL 上为 TPC-H 基准数据库做索引优化的全过程。

2. 重点在于：

   

   - 充分理解各经典 TPC-H 查询的过滤、分组、排序、关联条件；
   - 遵循“最左前缀”和“覆盖索引”原则，优先在高选择性字段与常用分组/排序字段上建立复合索引；
   - 用 EXPLAIN 系列命令对比优化前后 type、key、rows、Extra 等字段变化；
   - 用 EXPLAIN ANALYZE 获取真实运行指标，验证统计信息准确性。

   

3. 同时不能忽视索引对写入侧的影响：大表建宽索引会显著增加插入/更新成本，应当合理安排索引创建时机，并记录在报告中。

4. 最后，所有的索引设计与 DDL 操作都要配合 ANALYZE TABLE、SHOW PROCESSLIST、SHOW ENGINE INNODB STATUS 等命令做监控与验证，确保线上环境的性能与可用性不受严重影响。





希望以上示例和思路，能帮助你在 MySQL 上顺利完成 TPC-H 基准库的索引设计与查询执行计划分析，并将完整内容写入课程设计报告的第 6.4 节。如果还有具体的问题（如某条 TPC-H 查询的特殊改写、索引创建失败原因排查或 EXPLAIN 输出解读等），请随时告知。