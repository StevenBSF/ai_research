**局限与疑问：**

1. **因果假设方面：**

   - 如何合理化“内容”和“风格”可以完全可分的假设？是否存在某些本质上纠缠的因素（例如狗的品种与其典型风格相关）可能破坏解耦效果？
   - 诸如 $c \rightarrow Y^C$ 等因果方向是否经过实证验证？是否存在其他可行的因果图结构？
   - 本文未提供内容/风格分解的可辨性（identifiability）理论分析。在特定条件下，所提出的损失项是否能够保证语义因子的有效解耦?

2. **泛化能力与评估指标：**

   - 为何未报告如调整兰德指数（ARI）等指标？这是否会影响对聚类质量的全面判断？
   - 在视角数大于2（如 Caltech-all）的数据集上，性能提升是否在所有视角组合上都保持一致，还是仅对部分子集有效？
   - 十个数据集主要涵盖文本‑图像或图像‑图像组合，而不含时间序列、音频或图‑文本混合等异构场景  。请讨论方法对更复杂模态组合的可行性，并说明 causal content‑style 假设在不同模态下是否仍成立。

3. **噪声处理能力：**

   - 当前使用的高斯扰动策略假设噪声为加性，若遇到结构化噪声（如遮挡）或对抗性扰动，该方法是否依然有效？
   - 稀疏协方差正则项 $\mathcal{L}_{\text{SparseCov}}$ 在高维空间中是否存在估计偏差的问题？
   - 模型将噪声因素 $u_v$ 建模为无结构的变异。但在实际应用中，面对结构化噪声（如对抗扰动或系统性偏差），该方法能否有效处理?
   - 第 4.2 节通过高斯采样对特征均值和方差施加噪声  ，然而并未说明扰动方差 Σ_μ、Σ_σ 的设置原则及其对结果波动的影响。能否给出理论或经验依据来选择这些噪声尺度，并在多数据集上给出敏感性曲线？
   - DiffMapping 同时计算内容与噪声 Query‑Key 差分以消除噪声  ，但与已发表的差分 Transformer 或 Dual‑Attention 模块相比创新点尚不清晰。作者能否提供与这些方法的结构对照图和定量消融，以突出新增贡献？

4. **计算效率：**

   - 与基线方法相比，DiffMapping 的计算开销如何，尤其是在如 YouTubeFace（$N=101,499$）这样的大规模数据集上？
   - 论文仅给出“在 RTX A6000 GPU 上训练”以及默认学习率与批量大小，但缺乏对不同数据规模和视角数目下的实际训练时长、显存占用与参数量统计  。请作者报告完整的复杂度分析，并与 GCFAgg、DealMVC 等基线在同一硬件环境下做横向比较，以便评估可扩展性。
   - 双重差分内容-风格网络中引入了稀疏协方差正则等复杂操作。随着视角数量或特征维度的增加，计算复杂度如何扩展？

5. **参数敏感性：**

   - 虽然论文声称 $\lambda_1$ 和 $\lambda_2$ 对结果较为鲁棒，但 $\beta$ 的影响显著。在不进行穷举搜索的前提下，如何有效设定该参数？
   - DiffMapping 中的伪标签掩码阈值 τ_M 与对比学习温度 τ_c 均为固定常数（0.8 与 0.1）  。请作者系统分析不同阈值组合对性能与收敛性的影响，说明这些常数是否可在跨数据集迁移时保持稳定。
   - 图 6 只在 YoutubeFace 与 Wiki 上展示 λ₁、λ₂、β 的敏感性  。请作者补充对 Caltech-all 这类高维五视角数据集的同类实验，以验证结论的普适性。

6. **实际应用场景：**

   - 当各视角表达的语义高度异构（例如传感器数据 vs 文本）而非共享内容时，该方法的表现如何？

   - CausalMVC 是否支持视角缺失或仅部分对齐的情形，还是要求输入数据具备完整视角？

   - 当前实验默认所有样本在训练与测试阶段都拥有完整视角，但真实应用常出现视角缺失或异步到达。模型中的内容一致性和对比学习依赖完整伪标签图，作者能否展示在随机丢失视角、或测试阶段新增视角/删除视角情况下的适配策略与性能曲线？

   - 实验显示，在视角数增加时（如 Caltech-all）模型效果提升明显，但若视角异质性较强（如文本+图像+传感器数据），或存在视角缺失情况，该方法是否仍能保持良好性能？

   - 数据集如 CiteSeer 或 NoisyMNIST 中簇大小较均衡，而社交媒体、推荐系统数据常呈长尾分布。请补充在高度不平衡簇或动态簇数情况下的实验，检验内容‑风格解耦及对比损失是否对少数簇保持公平。

     

7. **对比学习策略：**

   - 内容中心的风格感受野是否可能抑制与风格相关的聚类线索（如图像中的光照条件），从而导致表示能力下降？

   - 对比损失（公式12）依赖于平均内容表示生成的伪标签。在训练初期，这些伪标签的准确性是否存在保障？

     

8. **分布漂移下的鲁棒性：**

   - 当训练与测试视角存在标签噪声或分布偏移时，模型的鲁棒性表现如何？

   

9. **最终聚类：**

   论文使用统一表征 U 经 k‑means 得到最终聚类标签  。若改用谱聚类或基于密度的方法，性能是否仍稳定？尤其当簇形状非球面或簇数未知时，依赖 k‑means 是否会限制模型的下游适用性？

   