![image-20241108133233157](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241108133233157.png)

## ***计算机学院（国家示范性软件学院)***

# 人工智能原理实验报告

## 词性标注

<center>姓名：包诗峰</center>
<center>学号：2022211656</center>
<center>班级：2022211301</center>

<div STYLE="page-break-after: always;"></div> 

## 实验内容

1. 学习掌握viterbi算法的实现原理，自行设计基于隐式马尔可夫的词性标注算法
2. 使用小白兔买菜的经过作为训练数据，训练算法
3. 使用训练之后的算法对“小白兔爱吃橙色的胡萝卜和嫩绿的青菜。”进行词性标注。

## 实验环境

- PyCharm
- Python 3.10

## 设计思路

- #### 方案设计

- ##### 方案引入

在词性标注任务中，隐马尔可夫模型 (HMM) 是一种常见的建模方法。HMM 使用三个概率分布：初始分布、状态转移矩阵和发射矩阵，结合 Viterbi 动态规划算法，能够高效地为句子中的每个单词预测最可能的词性标签。

  本实验的 HMM 模型包括以下关键步骤：
- **训练阶段**：从标注数据中统计初始状态分布、状态转移矩阵和发射矩阵。
- **预测阶段**：利用训练得到的参数和 Viterbi 算法，对输入句子进行词性标注。

为了便于实现，本实验采用 Python 和 Pandas 库来完成矩阵计算。

## 实验流程

#### 数据准备

- 标注数据格式：每行一个句子，每个单词和词性标签用斜杠 `/` 分隔，例如：

  ```bash
  回家/a 的/u 路上/n ，/w 小白兔/n 一边/d 哼着/v 小曲儿/n ，/w 一边/d 想象着/v 美味/a 的/u 午餐/n 。/w
  ```

​	•	其中，词性代码包括：

​	1.	t **时间词**

​	2.	w **标点符号**

​	3.	n **名词**

​	4.	v **动词**

​	5.	d **副词**

​	6.	a **形容词**

​	7.	u **助词**

​	8.	r **代词**



因此对于训练集，我们进行相应的标注，标注结果为：

```bash
清晨/t ，/w 小白兔/n 背着/v 一个/a 小篮子/n ，/w 来到/v 集市/n 上/d 买/v 菜/n 。/w
集市/n 上/d 人/n 很/d 多/a ，/w 摊位/n 上/d 摆满了/v 新鲜/a 的/u 蔬菜/n 水果/n 。/w
小白兔/n 的/u 鼻子/n 嗅了嗅/v ，/w 空气/n 里/d 弥漫着/v 各种/a 蔬菜/n 的/u 清香/n 。/w
它/n 蹦到/v 一个/a 摊位/n 前/d ，/w 眼睛/n 一下子/a 被/u 一堆/a 橙色/a 的/u 胡萝卜/n 吸引住了/v 。/w
“/w 真/d 漂亮/a 的/u 胡萝卜/n ！/w ”/w 小白兔/n 心想/v ，/w 伸出/v 前爪/n ，/w 挑起/v 一根/a 又长又直/a 的/u 胡萝卜/n 翻看起来/v 。/w
“/w 这/r 根/n 看起来/v 很甜/a ！/w 咦/w ，/w 那/r 根/n 也/d 不错/a ！/w ”/w 它/n 挑挑拣拣/v ，/w 不一会儿就/d 挑了/v 五六根/a 大小/a 均匀/a 的/u 胡萝卜/n 放进/v 篮子/n 里/d 。/w
挑完/v 胡萝卜/n ，/w 小白兔/n 又/d 走到/v 白菜摊/n 前/d ，/w 摸了/v 摸/v 圆润/a 的/u 白菜/n ，/w “/w 这个/r 可以做/v 汤/n ！/w ”/w
接着/d ，/w 它/r 又/d 挑了些/v 嫩绿/a 的/u 青菜/n ，/w “/w 这/r 青菜/n 炒/v 起来/v 一定/d 很/d 好吃/a ！/w ”/w
买完/v 菜/n 后/d ，/w 小白兔/n 掏/v 出/v 一个/a 小布袋/n ，/w 从里面/d 拿/v 出/v 几枚/a 亮晶晶/a 的/u 硬币/n ，/w 递给/v 摊主/n ，/w “/w 谢谢/v 您/r ，/w 胡萝卜/n 真/d 新鲜/a ！/w ”/w
摊主/n 笑呵呵/d 地/u 接过/v 硬币/n ，/w 送了/v 小白兔/n 一颗/a 香菜/n ，/w “/w 小白兔/n ，/w 下次/t 再/d 来/v 啊/d ！/w ”/w
回家/a 的/u 路上/n ，/w 小白兔/n 一边/d 哼着/v 小曲儿/n ，/w 一边/d 想象着/v 美味/a 的/u 午餐/n 。/w
```



#### HMM 模型的实现

隐马尔可夫模型 (HMM) 是词性标注任务中的经典方法，包含以下三个核心概率分布：

​	1.	**初始状态分布**：句子第一个词性可能的分布概率。

​	2.	**状态转移矩阵**：当前词性转移到下一个词性的概率。

​	3.	**发射矩阵**：某词性生成特定单词的概率。

模型设计包括两个主要阶段：

​	•	**训练阶段**：统计从标注数据中提取的概率分布，构建上述三个矩阵。

​	•	**预测阶段**：通过 Viterbi 算法计算最优路径，实现词性标注。

#### 核心模块及详细实现

##### 数据结构设计

```python
def __init__(self):
  self.transition_matrix = {} # 状态转移矩阵：记录词性之间的转移关系
  self.emission_matrix = {} # 发射矩阵：记录词性与单词之间的发射关系
  self.initial_distribution = {} # 初始分布：记录每种词性作为句子起始词性的频率
  self.pos_tags = [] # 存储所有可能的词性标签
  self.transition_totals = {} # 存储每种词性的转移总数，用于归一化概率
  self.emission_totals = {} # 存储每种词性生成单词的总数，用于归一化概率
```

​	•	**数据结构设计的目的**：

​			•	transition_matrix 和 emission_matrix 是主要统计矩阵，用于描述模型中两大核心概率分布（状态转移概率和发射概率）。

​			•	initial_distribution 用于记录初始状态分布。

​			•	transition_totals 和 emission_totals 是辅助统计变量，用于概率归一化。

##### 初始分布更新方法

```python
def __upd_start(self, pos):
  """更新初始状态分布"""
  if pos in self.initial_distribution:
   	self.initial_distribution[pos] += 1
	else:
  	self.initial_distribution[pos] = 1
```

​	•	**功能**：统计每种词性在句子起始位置出现的频率。

​	•	**设计意图**：初始分布是 HMM 的重要组成部分，它决定了句子第一个词性标注的概率。

##### 状态转移矩阵更新方法

```python
def __upd_trans(self, curpos, nxtpos):
  """更新状态转移矩阵"""
	if curpos in self.transition_matrix:
  	if nxtpos in self.transition_matrix[curpos]:
    	self.transition_matrix[curpos][nxtpos] += 1
    else:
      self.transition_matrix[curpos][nxtpos] = 1
  else:
    self.transition_matrix[curpos] = {nxtpos: 1}
```

​	•	**功能**：统计词性之间的转移频率，记录从 curpos 转移到 nxtpos 的次数。

​	•	**设计意图**：通过转移矩阵构建 HMM 的状态转移分布，用于描述不同词性之间的动态关系。

##### 发射矩阵更新方法

```python
def __upd_emit(self, pos, word):
  """更新发射矩阵"""
  if pos in self.emission_matrix:
    if word in self.emission_matrix[pos]:
      self.emission_matrix[pos][word] += 1
    else:
      self.emission_matrix[pos][word] = 1
  else:
    self.emission_matrix[pos] = {word: 1}
```

​	•	**功能**：统计某词性生成某单词的频率，记录词性 pos 发射单词 word 的次数。

​	•	**设计意图**：发射矩阵是 HMM 的另一核心部分，决定了词性如何与具体单词关联。

##### 5. 模型训练方法

```python
def train(self, data_path):
    """根据训练数据计算初始分布、转移矩阵和发射矩阵"""
    with open(data_path, 'r', encoding='utf-8') as f:
        for line in f.readlines():
            line = line.strip().split()
            self.__upd_start(line[0].split('/')[1])
            for i in range(len(line) - 1):
                self.__upd_emit(line[i].split('/')[1], line[i].split('/')[0])
                self.__upd_trans(line[i].split('/')[1], line[i + 1].split('/')[1])
            i = len(line) - 1
            self.__upd_emit(line[i].split('/')[1], line[i].split('/')[0])

    self.pos_tags = sorted(list(self.emission_matrix.keys()))
    self.transition_totals = {key: sum(self.transition_matrix[key].values()) for key in self.transition_matrix}
    self.emission_totals = {key: sum(self.emission_matrix[key].values()) for key in self.emission_matrix}

```

​	•	**功能**：

​			1. 逐行读取标注数据，更新初始分布、状态转移矩阵和发射矩阵。

​			2. 计算每种词性的总转移次数和总发射次数，用于后续概率归一化。

​	•	**设计流程**：

​			•	**起始词性统计**：取句子第一个单词的词性，更新初始分布。

​			•	**状态转移统计**：遍历句子中的词性对，更新状态转移矩阵。

​			•	**发射统计**：记录每个词性生成的单词，更新发射矩阵。



**6. Viterbi 算法实现**

```python
def Viterbi(self, sentence):
    """使用 Viterbi 算法进行词性标注"""
    sentence = sentence.strip().split()
    posnum = len(self.pos_tags)
    dp = pd.DataFrame(index=self.pos_tags)
    path = pd.DataFrame(index=self.pos_tags)
    start = []
    num_sentence = sum(self.initial_distribution.values()) + posnum

    for pos in self.pos_tags:
        sta_pos = self.initial_distribution.get(pos, 1e-16) / num_sentence
        sta_pos *= (self.emission_matrix[pos].get(sentence[0], 1e-16) /
                    self.emission_totals[pos])
        sta_pos = math.log(sta_pos)
        start.append(sta_pos)

    dp[0] = start
    path[0] = ['_start_'] * posnum

    for t in range(1, len(sentence)):
        prob_pos, path_point = [], []
        for i in self.pos_tags:
            max_prob, last_point = float('-inf'), ''
            emit = math.log(self.emission_matrix[i].get(sentence[t], 1e-16) / self.emission_totals[i])
            for j in self.pos_tags:
                tmp = dp.loc[j, t - 1] + emit
                tmp += math.log(self.transition_matrix[j].get(i, 1e-16) / self.transition_totals[j])
                if tmp > max_prob:
                    max_prob, last_point = tmp, j
            prob_pos.append(max_prob)
            path_point.append(last_point)
        dp[t], path[t] = prob_pos, path_point

    prob_list = list(dp[len(sentence) - 1])
    cur_pos = self.pos_tags[prob_list.index(max(prob_list))]
    path_que = [cur_pos]
    for i in range(len(sentence) - 1, 0, -1):
        cur_pos = path[i].loc[cur_pos]
        path_que.append(cur_pos)

    postag = []
    for i in range(len(sentence)):
        postag.append(sentence[i] + '/' + path_que[-i - 1])
    return postag
```

​	•	**功能**：

​			•	动态规划求解最优路径，生成每个单词的词性标注。

​	•	**设计细节**：

​			•	**初始化**：计算每个词性的起始概率和第一个单词的发射概率。

​			•	**转移过程**：递归计算每个时间步的最优路径及其概率。

​			•	**回溯路径**：根据动态规划表记录的路径，生成最终标注序列。



#### 测试结果

我们对于测试集语句进行测试，测试结果如下：
```bash
标注结果： ['小白兔/n', '爱/d', '吃/v', '橙色/a', '的/u', '胡萝卜/n', '和/d', '嫩绿/a', '的/u', '青菜/n', '。/w']
```

可以看到，`'爱'`应该标注成v，但是此处由于数据集较小，导致出现标注错误。

对于`'和'`，由于训练集不包括连词，因此也出现标注错误。

其余标注均正确。



## 实验总结

- ##### 遇到的问题

  - 词性标注较为麻烦，花了很长时间。
  - 在测试的语句上出现不正确的情况思考了很久。

- ##### 实验心得

  - 对于机器学习的经典算法有了更深的理解。

