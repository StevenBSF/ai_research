## 一、实验目的

使用神经网络或空间滤波方法去除图像中添加的高斯噪声。

## 二、设计思路

- 方案一：使用DnCNN进行去噪。
- 方案二：使用更大规模的基于Transformer针对图像去噪任务适配的Restormer进行去噪。

## 三、实验流程

- #### 方案一的设计

  - ##### 方案引入

    - 在图像去噪任务中，我们的目标是通过学习有噪声的图像和干净图像之间的映射来消除图像中的噪声。DnCNN模型采用了多层卷积网络，以解决经典的噪声消除问题。通过该模型，我们可以在网络层之间进行残差学习，使网络在减少噪声的同时尽量保持原始图像的细节。

      为了编程方便，我在实验中使用目前最主流的深度学习框架Pytorch。

  - ##### 数据输入的处理

    - **图像尺寸调整**：将所有图像统一调整为尺寸 `(256, 256)`，以便模型能够接受固定尺寸的输入。

      **数据增强**：在数据预处理过程中，我们将图像进行 `Resize` 和 `ToTensor` 转换，以便适应模型的输入要求。

  - ##### 模型设计

    - DnCNN模型采用了17层卷积结构，其中：

      **输入层**：

      - 使用一个3x3卷积核，输入通道为3（RGB三通道），输出通道为64个特征层，无偏置项。
      - 使用ReLU激活函数进行非线性变换，保留输入图像的噪声特征。

      **隐藏层**：

      - 中间共15层卷积层，卷积核大小为3x3，输出特征层数为64。每层卷积后接Batch Normalization层和ReLU激活函数。
      - Batch Normalization层用于标准化卷积层输出，减少训练不稳定性和梯度消失问题。

      **输出层**：

      - 最后一层卷积层，卷积核大小为3x3，输入通道为64，输出通道为3（与输入图像通道一致），用于生成去噪残差图。
      - 残差学习的设计思路是直接从噪声图像中减去噪声部分，得到去噪结果。

    - 编程设计如下：

      ```python
      class DnCNN(nn.Module):
          def __init__(self, channels=3, num_of_layers=17):
              super(DnCNN, self).__init__()
              kernel_size = 3
              padding = 1
              features = 64
              layers = []
      
              layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))
              layers.append(nn.ReLU(inplace=True))
      
              for _ in range(num_of_layers - 2):
                  layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))
                  layers.append(nn.BatchNorm2d(features))
                  layers.append(nn.ReLU(inplace=True))
      
              layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))
      
              self.dncnn = nn.Sequential(*layers)
      
          def forward(self, x):
              out = self.dncnn(x)
              return x - out
      
      ```

      

    - ###### 参数设置

      - **学习率**：选择 `1e-3` 的学习率。

        **批次大小**：批次大小为16。

        **训练轮数**：模型设置为训练50轮。

  - ##### 训练过程和结果

    - 实验使用的GPU是A6000，耗时约1小时左右。
    
    - 损失收敛效果如下：
      - ![image-20241103213809043](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103213809043.png)
      - ![output](/Users/baoshifeng/Downloads/output.png)
    
    - 训练集上PSNR为：27.66db
    
    - 生成的图像和test集提供的噪声图像PSNR值为：31.77db
    
    - 去噪效果展示
      - <img src="/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103141534529.png" alt="image-20241103141534529" style="zoom: 40%;" />![image-20241103141559244](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103141559244.png)
      - <img src="/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103141753699.png" alt="image-20241103141753699" style="zoom:48%;" />![image-20241103141818565](/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103141818565.png)
    

- #### 方案二的设计

  - 为了拓展对于目前大模型对于图像去噪的效果，我选取了CVPR 2022上的论文Restormer: Efficient Transformer for High-Resolution Image Restoration的架构在本次项目中的训练集进行微调。
  - 效果呈现
    - PSNR:32.02db
    - <img src="/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103142439373.png" alt="image-20241103142439373" style="zoom:50%;" /><img src="/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103142420619.png" alt="image-20241103142420619" style="zoom:50%;" />
    - <img src="/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103141753699.png" alt="image-20241103141753699" style="zoom:50%;" /><img src="/Users/baoshifeng/Library/Application Support/typora-user-images/image-20241103142523036.png" alt="image-20241103142523036" style="zoom:50%;" />
    - 可以看到同样的高斯噪声被成功消除。

## 四、实验总结

- ##### 遇到的问题

  - 使用Restormer训练的时候因为算力不够导致训练时间过长；
  - 在编写DnCNN代码的时候出现各种图像处理上的问题。

- ##### 解决方案

  - 对于Restormer进行微调。
  - 耐心Debug。

- ##### 实验心得

  - 对于图像去噪这一任务领域起初并不熟悉，但是通过查阅资料和近年的论文逐渐了解了主流的处理方法。
  - Pytorch编程能力提升了。

## 五、附录

- DnCNN实现代码

  - train.py

  - ```python
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import torchvision.transforms as transforms
    from torch.utils.data import DataLoader, Dataset
    from skimage.metrics import peak_signal_noise_ratio as psnr
    import numpy as np
    from PIL import Image
    import os
    
    class DenoisingDataset(Dataset):
        def __init__(self, clean_dir, noisy_dir, transform=None):
            self.clean_images = sorted(os.listdir(clean_dir))
            self.noisy_images = sorted(os.listdir(noisy_dir))
            self.clean_dir = clean_dir
            self.noisy_dir = noisy_dir
            self.transform = transform
    
            assert len(self.clean_images) == len(self.noisy_images), "干净图像和噪声图像数量不匹配"
    
        def __len__(self):
            return len(self.clean_images)
    
        def __getitem__(self, idx):
            clean_image_path = os.path.join(self.clean_dir, self.clean_images[idx])
            noisy_image_path = os.path.join(self.noisy_dir, self.noisy_images[idx])
    
            # 加载图像
            clean_image = Image.open(clean_image_path).convert('RGB')
            noisy_image = Image.open(noisy_image_path).convert('RGB')
    
            if self.transform:
                clean_image = self.transform(clean_image)
                noisy_image = self.transform(noisy_image)
    
            return noisy_image, clean_image
    
    
    class DnCNN(nn.Module):
        def __init__(self, channels=3, num_of_layers=17):
            super(DnCNN, self).__init__()
            kernel_size = 3
            padding = 1
            features = 64
            layers = []
    
            layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))
            layers.append(nn.ReLU(inplace=True))
    
            for _ in range(num_of_layers - 2):
                layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))
                layers.append(nn.BatchNorm2d(features))
                layers.append(nn.ReLU(inplace=True))
    
            layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))
    
            self.dncnn = nn.Sequential(*layers)
    
        def forward(self, x):
            out = self.dncnn(x)
            return x - out
    
    
    # 超参数
    num_epochs = 50
    learning_rate = 1e-3
    batch_size = 16
    
    # 定义图像尺寸
    desired_size = (256, 256)
    
    # 数据转换
    transform = transforms.Compose([
        transforms.Resize(desired_size),
        transforms.ToTensor(),
    ])
    
    # 数据集路径
    clean_dir = '/mnt/sda/baosf/data/Train/orign2'
    noisy_dir = '/mnt/sda/baosf/data/Train/noise'
    
    
    # 数据集和数据加载器
    dataset = DenoisingDataset(clean_dir, noisy_dir, transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = DnCNN().to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    for epoch in range(num_epochs):
        model.train()
        epoch_loss = 0
        for noisy_imgs, clean_imgs in dataloader:
            noisy_imgs = noisy_imgs.to(device)
            clean_imgs = clean_imgs.to(device)
    
            optimizer.zero_grad()
            outputs = model(noisy_imgs)
            loss = criterion(outputs, clean_imgs)
            loss.backward()
            optimizer.step()
    
            epoch_loss += loss.item()
    
        avg_epoch_loss = epoch_loss / len(dataloader)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')
    
    # 计算 PSNR
    def calculate_psnr(clean, denoised):
        clean = clean.cpu().numpy().astype(np.float32)
        denoised = denoised.cpu().numpy().astype(np.float32)
        psnr_value = psnr(clean, denoised, data_range=1.0)
        return psnr_value
    
    model.eval()
    psnr_total = 0
    with torch.no_grad():
        for noisy_imgs, clean_imgs in dataloader:
            noisy_imgs = noisy_imgs.to(device)
            clean_imgs = clean_imgs.to(device)
            outputs = model(noisy_imgs)
            for i in range(outputs.size(0)):
                psnr_value = calculate_psnr(clean_imgs[i], outputs[i])
                psnr_total += psnr_value
    
        avg_psnr = psnr_total / len(dataset)
        print(f'Average PSNR: {avg_psnr:.2f} dB')
    
    torch.save(model.state_dict(), 'denoising_dncnn.pth')
    ```

  - test.py

    ```python
    import torch
    import torch.nn as nn
    import torchvision.transforms as transforms
    from torch.utils.data import Dataset
    from PIL import Image
    import numpy as np
    import os
    from skimage.metrics import peak_signal_noise_ratio as psnr
    
    class TestDenoisingDataset(Dataset):
        def __init__(self, clean_dir, noisy_dir, transform=None, eval_transform=None):
            self.clean_images = sorted(os.listdir(clean_dir))
            self.noisy_images = sorted(os.listdir(noisy_dir))
            self.clean_dir = clean_dir
            self.noisy_dir = noisy_dir
            self.transform = transform  # 用于模型输入的转换
            self.eval_transform = eval_transform  # 用于评估的转换
    
            assert len(self.clean_images) == len(self.noisy_images), "干净图像和噪声图像数量不匹配"
    
        def __len__(self):
            return len(self.noisy_images)
    
        def __getitem__(self, idx):
            clean_image_path = os.path.join(self.clean_dir, self.clean_images[idx])
            noisy_image_path = os.path.join(self.noisy_dir, self.noisy_images[idx])
    
            # 加载图像
            clean_image = Image.open(clean_image_path).convert('RGB')
            noisy_image = Image.open(noisy_image_path).convert('RGB')
    
            # 保留原始尺寸
            original_size = clean_image.size  # (width, height)
    
            # 用于模型输入的转换（调整到训练时的尺寸）
            if self.transform:
                model_noisy_image = self.transform(noisy_image)
            else:
                model_noisy_image = transforms.ToTensor()(noisy_image)
    
            # 用于评估的转换（调整到统一尺寸）
            if self.eval_transform:
                eval_clean_image = self.eval_transform(clean_image)
                eval_denoised_image = self.eval_transform(noisy_image)
            else:
                eval_clean_image = transforms.ToTensor()(clean_image)
                eval_denoised_image = transforms.ToTensor()(noisy_image)
    
            return {
                'model_noisy_image': model_noisy_image,
                'eval_clean_image': eval_clean_image,
                'original_size': original_size,
                'noisy_image_path': noisy_image_path
            }
    
    class DnCNN(nn.Module):
        def __init__(self, channels=3, num_of_layers=17):
            super(DnCNN, self).__init__()
            kernel_size = 3
            padding = 1
            features = 64
            layers = []
    
            layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))
            layers.append(nn.ReLU(inplace=True))
    
            for _ in range(num_of_layers - 2):
                layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))
                layers.append(nn.BatchNorm2d(features))
                layers.append(nn.ReLU(inplace=True))
    
            layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))
    
            self.dncnn = nn.Sequential(*layers)
    
        def forward(self, x):
            out = self.dncnn(x)
            return x - out
    
    desired_size = (256, 256) 
    
    # 数据转换
    model_transform = transforms.Compose([
        transforms.Resize(desired_size),  
        transforms.ToTensor(),
    ])
    
    # 评估时的转换（统一尺寸）
    eval_transform = transforms.Compose([
        transforms.Resize(desired_size),
        transforms.ToTensor(),
    ])
    
    # 数据集路径
    clean_dir = '/mnt/sda/baosf/data/Test/output2/Real_Denoising'  
    noisy_dir = '/mnt/sda/baosf/data/Test/noise'   
    output_dir = '/mnt/sda/baosf/data/Test/output2/Real_Denoising'  
    
    
    assert os.path.isdir(clean_dir), f"干净图像路径不存在: {clean_dir}"
    assert os.path.isdir(noisy_dir), f"噪声图像路径不存在: {noisy_dir}"
    os.makedirs(output_dir, exist_ok=True)
    
    
    dataset = TestDenoisingDataset(clean_dir, noisy_dir, transform=model_transform, eval_transform=False)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    
    model = DnCNN().to(device)
    model.load_state_dict(torch.load('denoising_dncnn.pth', map_location=device))
    model.eval()
    
    # 计算 PSNR
    def calculate_psnr(clean, denoised):
        clean = clean.cpu().numpy().astype(np.float32)
        denoised = denoised.cpu().numpy().astype(np.float32)
        psnr_value = psnr(clean, denoised, data_range=1.0)
        return psnr_value
    
    psnr_total = 0
    with torch.no_grad():
        for data in dataloader:
            model_noisy_image = data['model_noisy_image'].to(device)
            eval_clean_image = data['eval_clean_image'].to(device)
            original_size = data['original_size'][0]  
            noisy_image_path = data['noisy_image_path'][0]
    
           
            output = model(model_noisy_image)
            output_image = output.squeeze().cpu().clamp(0, 1)
    
           
            output_image_pil = transforms.ToPILImage()(output_image)
    
    
    
            # 保存
            output_image_pil.save(os.path.join(output_dir, os.path.basename(noisy_image_path)))
    
            # 评估 
            denoised_for_eval = eval_transform(output_image_pil).to(device)
            psnr_value = calculate_psnr(eval_clean_image[0], denoised_for_eval)
            psnr_total += psnr_value
    
            print(f"Processed {os.path.basename(noisy_image_path)}, PSNR: {psnr_value:.2f} dB")
    
        avg_psnr = psnr_total / len(dataset)
        print(f'Average PSNR: {avg_psnr:.2f} dB')
    
    ```

    

